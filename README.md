## neuro_tank

# Выбор фреймворка
Используемый фреймворк - PyTorch. 
Выборка осуществлялась из трех фреймворков: Keras, Tensorflow и PyTorch.
Итоговый выбор пал на PyTorch по причине того, что он оказался самым удобным в использовании и довольно интуетивным. Вообще говоря, Keras тоже очень удобен, но документация у PyTorch крайне хорошо сделана. На данный момент PyTorch крайне быстро развивается, этому способстует тот факт, что его чаще выбирают в качестве фреймворка для ML в научных разработках и исследованиях, что также влияет на рост комьюнити PyTorch. Для подкрепления своих слов: https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/ 

# Выбор метода обучения
На текущий момент в проекте используется PolicyGradient Method (PG). 
Метод прост  в исполнении. Учится лучше чем QL (upd. похоже все учится лучше чем QL)
TODO: Подкрепить обосновение. Менее эффективное взаимодействие со средой --> дольше учится, плохо справляется с шумом. 
Перспективные методы: A2C, A3C, DDPG, TD3, SAC, PPO.

# Использованные ресурсы
1. Движок для битвы треугольников, автор - М.С. Товарнов;
2. Саймон Хайкин, Нейронные Сети полный курс;
3. Видеокурс с канала Machine Learning with Phil: https://www.youtube.com/channel/UC58v9cLitc8VaCjrcKyAbrw 
4. Скомунизженный курс https://neural-university.ru/

# Дальнейшее развитие
1. Доделать функцию обучения, чтобы она корректно работала
2. Пересмотреть варианты наград и наказаний --> значительно уменьшат время обучения, если охватывают разные аспекты обучения
3. Сделать столкновения с препяствиями (столкнулся = умер)
4. Сделать сохранение обученной модели
5. Поставить на обучение в компьютерный класс, как минимум на 500к эпизодов.



